{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"teaching\",\"teaching.1\"]]\n",
    "column_rename={\"teaching\":\"output\",\"teaching.1\":\"message\"}\n",
    "df.rename(columns=column_rename,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>intraction is good and leacture delivery also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>all the given terms are good regarding the uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>All the terms are good regarding the universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-1</td>\n",
       "      <td>Some of the teacher are un experienced. Also t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>IT IS GOING GOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     output                                            message\n",
       "0         0  teacher are punctual but they should also give...\n",
       "1         1                                              Good \n",
       "2         1  Excellent lectures are delivered by teachers a...\n",
       "3         1                                               Good\n",
       "4         1  teachers give us all the information required ...\n",
       "..      ...                                                ...\n",
       "180       1  intraction is good and leacture delivery also ...\n",
       "181       1  all the given terms are good regarding the uni...\n",
       "182       1  All the terms are good regarding the universit...\n",
       "183      -1  Some of the teacher are un experienced. Also t...\n",
       "184       1                                   IT IS GOING GOOD\n",
       "\n",
       "[185 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub(\"^a-zA-Z\",\" \",df[\"message\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"message\":corpus,\"output\":df[\"output\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Summary\",\"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.5608 - loss: 1.2260 - val_accuracy: 0.7568 - val_loss: 0.7940\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7195 - loss: 0.7426 - val_accuracy: 0.7568 - val_loss: 0.7583\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7186 - loss: 0.6451 - val_accuracy: 0.7568 - val_loss: 0.6972\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7757 - loss: 0.5666 - val_accuracy: 0.7838 - val_loss: 0.6937\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8883 - loss: 0.4910 - val_accuracy: 0.7838 - val_loss: 0.7588\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8902 - loss: 0.5280 - val_accuracy: 0.7297 - val_loss: 0.7524\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9291 - loss: 0.3922 - val_accuracy: 0.7027 - val_loss: 0.7288\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9184 - loss: 0.3722 - val_accuracy: 0.7297 - val_loss: 0.7811\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9149 - loss: 0.3046 - val_accuracy: 0.7027 - val_loss: 0.9249\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub(\"^a-zA-Z\",\" \",df[\"message\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",patience=5,restore_best_weights=True)\n",
    "\n",
    "X = df[\"message\"]\n",
    "y = df[\"output\"]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "y_train_shifted = to_categorical(y_train,num_classes=3)\n",
    "y_test_shifted = to_categorical(y_test,num_classes=3)\n",
    "\n",
    "X_train_transformed = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128,activation=\"relu\",kernel_regularizer=l2(0.001),input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64,activation=\"relu\",kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(3,activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train_transformed,y_train_shifted,epochs = 20,batch_size=32,validation_data=(X_test_transformed,y_test_shifted),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Dataset-SA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Summary\"]\n",
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = lbl_encoder.fit_transform(y_train)\n",
    "y_test_encoded = lbl_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/205052 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205052/205052 [04:58<00:00, 687.29it/s] \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "corpus = []\n",
    "X = X.astype(str).fillna(\"\")\n",
    "for i in tqdm(range(len(df))):\n",
    "    review = re.sub(\"[^a-zA-Z]\",\" \",X.iloc[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"message\":corpus,\"output\":y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/lematized_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cooler excellent air flow price amazing ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best budget fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality good power air decent</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad product fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205047</th>\n",
       "      <td>good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205048</th>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205049</th>\n",
       "      <td>nice fast delivery</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205050</th>\n",
       "      <td>awesome product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205051</th>\n",
       "      <td>good mixing bowl included one disappointmentan...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205052 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  message    output\n",
       "0       great cooler excellent air flow price amazing ...  positive\n",
       "1                     best budget fit cooler nice cooling  positive\n",
       "2                           quality good power air decent  positive\n",
       "3                                         bad product fan  negative\n",
       "4                                           ok ok product   neutral\n",
       "...                                                   ...       ...\n",
       "205047                                       good product  positive\n",
       "205048                                               nice  positive\n",
       "205049                                 nice fast delivery  positive\n",
       "205050                                    awesome product  positive\n",
       "205051  good mixing bowl included one disappointmentan...   neutral\n",
       "\n",
       "[205052 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/lematized_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "output\n",
       "positive    166581\n",
       "negative     28232\n",
       "neutral      10239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"output\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"message\"]\n",
    "X = X.astype(str).fillna(\"\")\n",
    "y = df[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2),max_features=50000)\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded_lbl = encoder.fit_transform(y_train)\n",
    "y_test_encoded_lbl = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_encoded_onehot = to_categorical(y_train_encoded_lbl)\n",
    "y_test_encoded_onehot = to_categorical(y_test_encoded_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 1078770 stored elements and shape (164041, 50000)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",patience=3,restore_best_weights=True)\n",
    "model = Sequential([\n",
    "    Dense(128,activation=\"relu\",input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dropout(0.25),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(3,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1282/1282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 111ms/step - accuracy: 0.8849 - loss: 0.3701 - val_accuracy: 0.9217 - val_loss: 0.2362\n",
      "Epoch 2/20\n",
      "\u001b[1m1282/1282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 114ms/step - accuracy: 0.9386 - loss: 0.1881 - val_accuracy: 0.9201 - val_loss: 0.2460\n",
      "Epoch 3/20\n",
      "\u001b[1m1282/1282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 111ms/step - accuracy: 0.9510 - loss: 0.1525 - val_accuracy: 0.9175 - val_loss: 0.2733\n",
      "Epoch 4/20\n",
      "\u001b[1m1282/1282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 109ms/step - accuracy: 0.9576 - loss: 0.1324 - val_accuracy: 0.9177 - val_loss: 0.3022\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_transformed,y_train_encoded_onehot,validation_data=(X_test_transformed,y_test_encoded_onehot),epochs=20,batch_size=128,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "model.save(\"models/final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1282/1282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      5557\n",
      "           1       0.75      0.46      0.57      2033\n",
      "           2       0.95      0.98      0.96     33421\n",
      "\n",
      "    accuracy                           0.92     41011\n",
      "   macro avg       0.83      0.73      0.77     41011\n",
      "weighted avg       0.92      0.92      0.92     41011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "print(classification_report(y_test_encoded_lbl, y_pred.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models/vectorizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vectorizer,file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
