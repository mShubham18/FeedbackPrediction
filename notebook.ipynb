{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1 -> bad<br>\n",
    "0 -> neutral<br>\n",
    "1 -> good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>teaching.1</th>\n",
       "      <th>coursecontent</th>\n",
       "      <th>coursecontent.1</th>\n",
       "      <th>examination</th>\n",
       "      <th>Examination</th>\n",
       "      <th>labwork</th>\n",
       "      <th>labwork.1</th>\n",
       "      <th>library_facilities</th>\n",
       "      <th>library_facilities</th>\n",
       "      <th>extracurricular</th>\n",
       "      <th>extracurricular.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>content of courses are average</td>\n",
       "      <td>1.0</td>\n",
       "      <td>examination pattern is good</td>\n",
       "      <td>-1</td>\n",
       "      <td>not satisfactory, lab work must include latest...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>library facilities are good but number of book...</td>\n",
       "      <td>1</td>\n",
       "      <td>extracurricular activities are excellent and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Not good</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Not good</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>All courses material provide very good knowled...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Exam pattern is up to the mark and the Cgpa de...</td>\n",
       "      <td>1</td>\n",
       "      <td>Lab work is properly covered in the labs by th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Library facilities are excellent in terms of g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Extra curricular activities also help students...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Content of course is perfectly in line with th...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Again the university tests students of their a...</td>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Its the best thing i have seen in this univers...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Complete wastage of time. Again this opinion i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>content of courses improves my knowledge</td>\n",
       "      <td>1.0</td>\n",
       "      <td>examination pattern is good</td>\n",
       "      <td>1</td>\n",
       "      <td>practical work provides detail knowledge of th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>library has huge collection of books from diff...</td>\n",
       "      <td>1</td>\n",
       "      <td>extracurricular activities increases mental an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   teaching                                         teaching.1  coursecontent  \\\n",
       "0         0  teacher are punctual but they should also give...            0.0   \n",
       "1         1                                              Good            -1.0   \n",
       "2         1  Excellent lectures are delivered by teachers a...            1.0   \n",
       "3         1                                               Good           -1.0   \n",
       "4         1  teachers give us all the information required ...            1.0   \n",
       "\n",
       "                                     coursecontent.1  examination  \\\n",
       "0                     content of courses are average          1.0   \n",
       "1                                           Not good          1.0   \n",
       "2  All courses material provide very good knowled...          1.0   \n",
       "3  Content of course is perfectly in line with th...         -1.0   \n",
       "4           content of courses improves my knowledge          1.0   \n",
       "\n",
       "                                         Examination  labwork  \\\n",
       "0                        examination pattern is good       -1   \n",
       "1                                               Good        1   \n",
       "2  Exam pattern is up to the mark and the Cgpa de...        1   \n",
       "3  Again the university tests students of their a...        1   \n",
       "4                        examination pattern is good        1   \n",
       "\n",
       "                                           labwork.1  library_facilities  \\\n",
       "0  not satisfactory, lab work must include latest...                 0.0   \n",
       "1                                              Good                 -1.0   \n",
       "2  Lab work is properly covered in the labs by th...                 1.0   \n",
       "3                                               Good                 0.0   \n",
       "4  practical work provides detail knowledge of th...                 1.0   \n",
       "\n",
       "                                  library_facilities  extracurricular  \\\n",
       "0  library facilities are good but number of book...                1   \n",
       "1                                          Not good                 1   \n",
       "2  Library facilities are excellent in terms of g...                1   \n",
       "3  Its the best thing i have seen in this univers...               -1   \n",
       "4  library has huge collection of books from diff...                1   \n",
       "\n",
       "                                   extracurricular.1  \n",
       "0  extracurricular activities are excellent and p...  \n",
       "1                                              Good   \n",
       "2  Extra curricular activities also help students...  \n",
       "3  Complete wastage of time. Again this opinion i...  \n",
       "4  extracurricular activities increases mental an...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"teaching\",\"teaching.1\"]]\n",
    "column_rename={\"teaching\":\"output\",\"teaching.1\":\"message\"}\n",
    "df.rename(columns=column_rename,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output                                            message\n",
       "0       0  teacher are punctual but they should also give...\n",
       "1       1                                              Good \n",
       "2       1  Excellent lectures are delivered by teachers a...\n",
       "3       1                                               Good\n",
       "4       1  teachers give us all the information required ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to feedpred/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "nltk.download(\"stopwords\", download_dir=\"feedpred/nltk_data\")\n",
    "os.environ[\"NLTK_DATA\"] = os.path.join(os.getcwd(), \"nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "os.environ[\"NLTK_DATA\"] = os.path.join(os.getcwd(), \"nltk_data\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub(\"^a-zA-Z\",\" \",df[\"message\"][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    review = \" \".join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[\"message\"]\n",
    "y = df[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[\"message\"]\n",
    "y = df[\"output\"]\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14624\\2739233981.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_train.toarray()\n",
      "\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6295\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6296\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m         ):\n\u001b[32m   6298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultinomialNB.__init__() got an unexpected keyword argument 'multi_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnaive_bayes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultinomialNB\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mMultinomialNB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43movo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m model.fit(X_train_transformed,y_train)\n\u001b[32m      4\u001b[39m y_pred_train = model.predict(X_train_transformed)\n",
      "\u001b[31mTypeError\u001b[39m: MultinomialNB.__init__() got an unexpected keyword argument 'multi_class'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_transformed,y_train)\n",
    "y_pred_train = model.predict(X_train_transformed)\n",
    "y_pred_test = model.predict(X_test_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: \n",
      "\n",
      "\n",
      "accuracy_score_train : 0.7837837837837838\n",
      "Testing Accuracy: \n",
      "\n",
      "\n",
      "accuracy_score_test : 0.7567567567567568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score\n",
    "accuracy_score_train = accuracy_score(y_train,y_pred_train)\n",
    "#roc_auc_score_train = roc_auc_score(y_train,y_pred_train)\n",
    "print(\"Training Accuracy: \\n\\n\")\n",
    "print(f\"accuracy_score_train : {accuracy_score_train}\")\n",
    "#print(f\"roc_auc_score_train: {roc_auc_score_train}\")\n",
    "\n",
    "accuracy_score_test = accuracy_score(y_test,y_pred_test)\n",
    "#roc_auc_score_test = roc_auc_score(y_test,y_pred_test)\n",
    "print(\"Testing Accuracy: \\n\\n\")\n",
    "print(f\"accuracy_score_test : {accuracy_score_test}\")\n",
    "#print(f\"roc_auc_score_test: {roc_auc_score_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(model_name):\n",
    "    model = model_name\n",
    "    model.fit(X_train_transformed,y_train)\n",
    "    y_pred_train = model.predict(X_train_transformed)\n",
    "    y_pred_test = model.predict(X_test_transformed)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score,roc_auc_score,precision_score\n",
    "    accuracy_score_train = accuracy_score(y_train,y_pred_train)\n",
    "    #roc_auc_score_train = roc_auc_score(y_train,y_pred_train)\n",
    "    print(\"Training Accuracy: \\n\\n\")\n",
    "    print(f\"accuracy_score_train : {accuracy_score_train}\")\n",
    "    #print(f\"roc_auc_score_train: {roc_auc_score_train}\")\n",
    "\n",
    "    accuracy_score_test = accuracy_score(y_test,y_pred_test)\n",
    "    #roc_auc_score_test = roc_auc_score(y_test,y_pred_test)\n",
    "    print(\"Testing Accuracy: \\n\\n\")\n",
    "    print(f\"accuracy_score_test : {accuracy_score_test}\")\n",
    "    #print(f\"roc_auc_score_test: {roc_auc_score_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher are punctual but they should also give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent lectures are delivered by teachers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>teachers give us all the information required ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   output                                            message\n",
       "0       0  teacher are punctual but they should also give...\n",
       "1       1                                              Good \n",
       "2       1  Excellent lectures are delivered by teachers a...\n",
       "3       1                                               Good\n",
       "4       1  teachers give us all the information required ..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128,activation=\"relu\",input_shape=(X_train.shape[0],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(3,activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"adam\",loss=\"Categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train_transformed,y_train,epochs = 20,batch_size=32,validation_data=(X_test_transformed,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 148, but received input with shape (None, 2029)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 2029), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:227\u001b[39m, in \u001b[36massert_input_compatibility\u001b[39m\u001b[34m(input_spec, inputs, layer_name)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec.axes.items():\n\u001b[32m    223\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m    224\u001b[39m             value,\n\u001b[32m    225\u001b[39m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    226\u001b[39m         }:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    228\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of layer \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m is \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    229\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    230\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    231\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mbut received input with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    232\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    233\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 148, but received input with shape (None, 2029)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 2029), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in y:\n",
    "    if value==-1:\n",
    "        y= y.replace(value,0)\n",
    "    elif value==0:\n",
    "        y=y.replace(value,1)\n",
    "    else:\n",
    "        y=y.replace(value,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Documents\\FeedbackPrediction\\feedpred\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.5434 - loss: 1.0856 - val_accuracy: 0.7568 - val_loss: 1.0449\n",
      "Epoch 2/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7107 - loss: 1.0235 - val_accuracy: 0.7568 - val_loss: 0.9854\n",
      "Epoch 3/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6909 - loss: 0.9615 - val_accuracy: 0.7568 - val_loss: 0.9172\n",
      "Epoch 4/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7259 - loss: 0.8609 - val_accuracy: 0.7568 - val_loss: 0.8389\n",
      "Epoch 5/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7069 - loss: 0.7629 - val_accuracy: 0.7568 - val_loss: 0.7587\n",
      "Epoch 6/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7267 - loss: 0.6491 - val_accuracy: 0.7568 - val_loss: 0.6908\n",
      "Epoch 7/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7295 - loss: 0.5577 - val_accuracy: 0.7568 - val_loss: 0.6436\n",
      "Epoch 8/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7264 - loss: 0.4618 - val_accuracy: 0.7568 - val_loss: 0.6134\n",
      "Epoch 9/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7696 - loss: 0.3880 - val_accuracy: 0.7568 - val_loss: 0.5945\n",
      "Epoch 10/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8608 - loss: 0.3509 - val_accuracy: 0.8108 - val_loss: 0.5662\n",
      "Epoch 11/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9028 - loss: 0.3118 - val_accuracy: 0.8108 - val_loss: 0.5483\n",
      "Epoch 12/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9729 - loss: 0.2370 - val_accuracy: 0.8108 - val_loss: 0.5351\n",
      "Epoch 13/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9566 - loss: 0.2165 - val_accuracy: 0.8108 - val_loss: 0.5120\n",
      "Epoch 14/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9948 - loss: 0.1626 - val_accuracy: 0.8108 - val_loss: 0.4886\n",
      "Epoch 15/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9850 - loss: 0.1470 - val_accuracy: 0.8108 - val_loss: 0.4703\n",
      "Epoch 16/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9923 - loss: 0.1096 - val_accuracy: 0.8108 - val_loss: 0.4631\n",
      "Epoch 17/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0838 - val_accuracy: 0.8378 - val_loss: 0.4570\n",
      "Epoch 18/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0907 - val_accuracy: 0.8378 - val_loss: 0.4495\n",
      "Epoch 19/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0559 - val_accuracy: 0.8378 - val_loss: 0.4491\n",
      "Epoch 20/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0450 - val_accuracy: 0.8378 - val_loss: 0.4471\n",
      "Epoch 21/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.8378 - val_loss: 0.4419\n",
      "Epoch 22/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0348 - val_accuracy: 0.8378 - val_loss: 0.4385\n",
      "Epoch 23/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0365 - val_accuracy: 0.8378 - val_loss: 0.4442\n",
      "Epoch 24/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0237 - val_accuracy: 0.8378 - val_loss: 0.4447\n",
      "Epoch 25/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 0.8378 - val_loss: 0.4487\n",
      "Epoch 26/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.8378 - val_loss: 0.4497\n",
      "Epoch 27/30\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0204 - val_accuracy: 0.8378 - val_loss: 0.4542\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\",patience=5,restore_best_weights=True)\n",
    "\n",
    "X = df[\"message\"]\n",
    "y = df[\"output\"]\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "y_train_shifted = to_categorical(y_train,num_classes=3)\n",
    "y_test_shifted = to_categorical(y_test,num_classes=3)\n",
    "\n",
    "X_train_transformed = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_transformed = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128,activation=\"relu\",input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dropout(0.12),\n",
    "    Dense(64,activation=\"relu\"),\n",
    "    Dropout(0.12),\n",
    "    Dense(3,activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train_transformed,y_train_shifted,epochs = 30,batch_size=16,validation_data=(X_test_transformed,y_test_shifted),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train_shifted = to_categorical(y_train,num_classes=3)\n",
    "y_test_shifted = to_categorical(y_test,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model.save(\"models/model.h5\")\n",
    "with open(\"models/vectorizer.pkl\",\"wb\") as file:\n",
    "    pickle.dump(vectorizer,file)\n",
    "with open(\"models/lemmatizer.pkl\",\"wb\") as file:\n",
    "    pickle.dump(lemmatizer,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models/lemmatizer.pkl\",\"wb\") as file:\n",
    "    pickle.dump(lemmatizer,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (np.array(X_train).reshape(-1,1))\n",
    "X_test = (np.array(X_train).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
